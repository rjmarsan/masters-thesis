\chapter{Malware on Android}
\label{sec:malware}

Malware on mobile devices has seen a departure from past exploits. The wealth of Personally Identifiable Information easily available on mobile OSs has made them the increased focus of malicious software. In addition, the tight sandboxing constraints have often forced malware writers to either find exploits to break out of the sandbox, or to write malware that cloaks itself as benign. Without finding exploits, code may not be ran by the user unless it is in \textit{app} form, and come through a trusted channel (unless that security feature has been disabled). This has caused two main vectors of attack: finding exploits to remotely install software, or masquerade as benign apps, and pass through trusted channels. On Android, this last technique is especially popular. 

After masquerading as a benign app, malware on Android has three main techniques: privilege escalation attacks, monetary service attacks, and PII stealing attacks. The first one, privilege escalation attacks, takes many forms on android. The basic premise is simple: acquire access to operations beyond what the sandbox and granted capabilities provide. The main way to accomplish this is via \textit{rooting}.

\section{Privilege Escalation Attack}
\subsection{Rooting}
Rooting is the act of acquiring root privileges on an OS. Typically mobile OSs do not provide the user, or apps, with root permissions, and instead reserve that for a set of trusted system processes. However, by finding vulnerabilities in these services, or exploiting the OS itself, apps can escape the sandbox. After an app has been granted root capabilities, the permission system no longer applies to it: it can simply access whatever it wants. These attacks are difficult for the system to detect: all monitoring of apps relies on monitoring the sandbox - when an app escapes that, there's no tracking it. This technique is commonly employed by botnets - giving remote access to the core system. 

Many examples of root exploits exist, dating back to 2011 with \textit{RageAgainstTheCage}\citep{droiddream}. These root exploits were very popular for non-malicious purposes, circumventing the device's sandbox to install a permanent root binary, creating a similar setup to a typical UNIX computer, where root may be acquired after a password/permission. However, in March 2011, DroidDream was discovered. DroidDream used \textit{RageAgainstTheCage} to silently install additional applications in the background. From there, it proceeded to steal PII and become a botnet. By the time it was remotely removed from the market, it had been downloaded an estimated 50,000 to 200,000 times\citep{castillo2010android} - the largest bulk-remote-removal of apps seen from the GPStore. From then on, a stream of root exploit malware was found, based off of \textit{RageAgainstTheCage}, \textit{udev}, and one exploit called \textit{GingerMaster}\citep{gingermaster}.

\textit{GingerMaster} is significant because it is the last known root exploit malware seen in the wild. Designed for Android 2.3.3, it can currently run on 45\% of all Android devices in use, according to the official Android Dashboard\citep{androiddashboard}. However, in reality, of that 45\%, almost all of them run Android 2.3.3 or higher, and virtually all have been patched to fix the exploit. All previous exploits were patched in Android 2.3, meaning less than 6\% of all active Android devices are vulnerable to them. Since Android 4.0, Google has focused greatly on security, improving ASLR and patching system services. No known rootkits exist - malicious or not - for Android 4.0 and up - 54\% of active Android devices.

 %Several exploits became very popular for malware writers, starting with DroidDream in 2010 <cite>, then RageAgainstTheCage, PSNeuter, and GingerBreak. When DroidDream was first discovered, it was downloaded over <50,000> times in the GPStore - prompting the largest bulk-remote-removal of apps Google has ever been discovered to have performed. However, most of these attacks have been fixed by vendors as of Android 2.3.3 - meaning the total amount of current devices in use that are vulnerable to these bugs being roughly <10%>. After these attacks, Android has taken definite steps to up its security. Since 4.0, proper ASLR has been implemented, as well as other security enhancements. There has been no known malware written for Android 4.0 and up - over <50%> of the active market.

\subsection{Confused Deputy Attack}
The second main vector for privilege escalation attacks is the Confused Deputy attack\citep{hardy1988confused}. In this scenario, services that guard sensitive operations are ``tricked'' into performing them. An example of this would be if a Content Provider forgot to check a permission, or finding APIs that do not correctly perform a permission check. Perhaps the simplest example of this is the ability for any Android app to contact remote servers, simply by asking the web browser to open a Url. By passing sensitive data in the URL, an app may still contact a remote server without ever requesting the \textit{INTERNET permission}. Projects like XManDroid\citep{bugiel2011xmandroid} and Quire\citep{dietz2011quire} address this by extending Android to analyze inter-app communication and detect this kind of attack. Despite all of these concerns, it's worth noting that no known malware has been used to exploit this. 

\section{Monetary Service Attack}
The second malware technique is possibly the simplest: perform services on behalf of the user that cost money. Examples of this include calling costly phone numbers and sending premium SMS messages. Typically these actions are performed without notifying the user, and only visible after the user checks their sent messages, or calls. These attacks have been prevalent in the Android market for quite a while, but recent versions of android - after 4.2 Jelly Bean - have taken the step of warning the user before premium SMSs are sent. This attack vector, while common, will see a reduction in the future thanks to these measures.

\temp{Expand on this more}


\section{Private Info Theft}
The last malware technique is the most significant, and represents the largest departure from typical malware. Apps that steal PII, or Info Theft Malware. The theme is fairly straightforward: Provide the user with a seemingly legitimate app, but in the background acquire large amounts of valuable data, from call logs to contacts to photos, and send them to a remote server. This fits in well with the main themes of mobile computing: the consolidation of many sources of PII all in one device. However, this is the biggest departure from typical malware. To the system, no unusual operations are performed, and no exploits are ran. The qualification for malware in this category thus lies in the ``use'' vs ``misuse'' of PII. Often times, this line is blurred.

A large distinction in what constitutes as privacy malware to an individual stems from their expectations of how the app will use their PII. Consider the case of the Path iPhone app, which in Feb 2012 was discovered to be uploading the user's entire contact list to Path's servers, without any permission from the user\citep{thampi2012}. It's fairly uncontroversial for a social network to read your contact data, and the act of scanning contacts to help ``find your friends'' on Path wasn't out of the ordinary. As VentureBeat discovered: ``Facebook, Twitter, Instagram, Foursquare, Foodspotting, Yelp, and Gowalla are among a smattering of iOS applications that have been sending the actual names, email addresses and/or phone numbers from your device's internal address book to their servers''\citep{vb2012addressbook}. Ultimately, however, the outrage was sparked because of how unexpected the behavior was.

The Path incident sparked several key changes in iOS's security model: specifically, having a popup occur when an app requests access to the contacts database, and allowing the user to reject the request. This, in general, is a one-time request, after which the app is given free reign over content\citep{AppleContacts}, which doesn't fully address situations like Path, where it's less about the app simply having access to the data, but what the app actually did with the data behind the scenes. When these actions did not match up with user expectations, it was treated as malware until the situation was cleared up by Path. The next day, they issued an update immediately explaining to the user what they were going to do with the data, and why.

It's worth noting that the only reason Path's contacts upload mechanism was discovered was by accident: Arun Thampi discovered it as part of a company hackathon, and only via sniffing the HTTP requests coming from the phone. An ordinary smartphone user would not have access to these tools, nor have the time and patience to sift through the data to spot unusual behavior.

\section{User-App Agreement}
This incident, however, lies at the heart of mobile malware: Misuse of PII lies in the abstract definition of how the app is expected to behave. Apps that violate this expectation of behavior are classified as malware, and apps that do not are not. This agreement between the user and the app, the User-App Agreement, or UAA, is an informal understanding the user has as to what actions an app will take. This differs from the Permission Fingerprint, which is a measure of what actions the app is capable of performing, instead dealing with exactly when and how those actions are taken. Since this agreement is not formally defined, it's acquired through external trust in an app. This happens in various ways, through the description the app provides, to the knowledge and referral of the app from other trusted sources, or the trust in the developer. The UAA is not a measure of how trustworthy an app is, but rather a framework for consenting and trusting specific actions an app may take.

An example of UAA can be seen in the expected behavior of two different hypothetical apps and a hypothetical user. One is a large Social Networking app, which requests permission to access internet, send SMS messages and read the contacts database. The other is a little known developer's game, which also requests permission to access internet, send SMS messages and read contacts. These apps have the same Permission Fingerprint, but the exact behavior of how they access these capabilities may or may not violate the UAA. If the Social Networking app accesses contacts when the user requests it ``find my friends'', and it sends SMS messages after the user messages another user who is not ``online'', these actions fall within the UAA of the Social Networking app and the user. However, if the contacts database is read and uploaded to a remote server without the consent of the user, this will violate the UAA (building off the example of Path). 

In the case of the game, these documented capabilities in the Permission Fingerprint may be enough to violate the UAA: the user may not trust an app with the capability of these actions. However, in the case that the user does, or simply doesn't pay attention, the app still may not violate the UAA. If the app is an online game, and asks you to find other people you know who are playing it, this would more likely than not fall within the UAA. However, if it sends SMS messages to your friends telling them to download the game, this would quickly violate the UAA.

In both examples, the apps have the exact same Permission Fingerprint, but vary wildly in their expected behavior, and which actions are trusted and untrusted. This fits right along with our definition of malware, with the misuse of PII and other device capabilities. This also highlights the shortcomings of the Permissions framework - being unable to deal with the subtle differences between trusted behavior and untrusted behavior. Indeed, for any given user, they may have a very different understanding of what acceptable behavior is. Therefore, UAA plays a crucial role in classifying apps in relation to Info Theft Malware.

\section{Research Malware}
In the realm of research malware, several prominent examples further demonstrate the vague line between use and misuse of PII, and the User-App Agreement. The most notable one is SoundComber\citep{schlegel2011soundcomber} It passes off as a benign app, but in the background records audio, and does on-phone processing to find sensitive PII, after which it uploads the information to a remote server. This app is unique because of its simple Permission Fingerprint, and its ability to gather sensitive PII from a channel not suspected to be very rich in PII.

The second prominent example of research malware on Android is TapLogger\citep{xu2012taplogger}. TapLogger imitates a simple touch-based game, learning the vibration patterns of the device for each tap. After which, TapLogger records the vibration patterns in the background, attempting to discover passwords and other sensitive keyboard events, all through a seemingly trusted sensor. TapLogger requests no Permissions, therefore its behavior is a possible behavior of virtually all apps. 

\section{Malware Summary}
The landscape of malware on android follows many clear patterns. The first is the use of masquerading as benign apps, and passing through trusted/semi-trusted channels to enter the device. Once on the device, the three main categories of attacks are privilege escalation attacks, monetary service attacks, and Info theft. Of these three attacks, privilege escalation and monetary service attacks are the easiest to protect against, and indeed Android has taken serious steps to mitigate these. However, the third time of attack, Info theft, is the most difficult to mitigate on Android, due to the shortcomings of the Permissions framework, and the wide spectrum of severity these attacks can take. Since these attacks may vary in interpretation per user, and lay in the subtle communication between the user and the app, we highlight the need for a concise UAA, where the user can evaluate the actions themselves.
